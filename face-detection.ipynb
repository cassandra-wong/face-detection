{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given facial data, the goal of this notebook is to write a program to fit a logistic regression model to the training data to recognize human faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data for facial detection\n",
    "The file `faces.mat` is composed of `train_faces`, `train_nonfaces`, `test_faces`, and `test_nonface`. Training dataset is constructed to be a 361 by 4858 matrix, and test data is constructed to be a 361 by 944 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = loadmat('faces.mat')\n",
    "\n",
    "train_faces, train_nonfaces = faces['train_faces'], faces['train_nonfaces']\n",
    "test_faces, test_nonfaces = faces['test_faces'], faces['test_nonfaces']\n",
    "\n",
    "# Training data, with face as 1 and non-face as 0\n",
    "X_train = np.vstack([train_faces, train_nonfaces])\n",
    "y_train = np.vstack([np.ones(train_faces.shape[0]).reshape(-1,1),\n",
    "                     np.zeros(train_faces.shape[0]).reshape(-1,1)])\n",
    "\n",
    "# Testing data, with face as 1 and non-face as 0\n",
    "X_test = np.vstack([test_faces, test_nonfaces])\n",
    "y_test = np.vstack([np.ones(test_faces.shape[0]).reshape(-1,1),\n",
    "                     np.zeros(test_faces.shape[0]).reshape(-1,1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid function: used to compute pi's in subsequent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (np.exp(x) / (1 + np.exp(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector p maps training samples with their corresponding $p_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_vector(X,beta):\n",
    "    p = np.zeros(X.shape[0]).reshape(-1,1)\n",
    "    for i in np.arange(0,X.shape[0]):\n",
    "        X_i = X[i,:].reshape(-1,1)\n",
    "        p[i] = sigmoid(beta.T @ X_i)\n",
    "    return p.reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Euclidean norm is used to test convergence, has the formula $||x-y||_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,y):\n",
    "    return np.sqrt(np.sum(np.power(x-y,2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Newton-Raphson method is to find estimate $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def get_beta(X,y, max_iter = 300, tol = 1e-10):\n",
    "    converged, count = False, 0\n",
    "    beta = np.zeros(X_train.shape[1]).reshape(-1,1)\n",
    "    \n",
    "    while not converged:\n",
    "        p = p_vector(X,beta)\n",
    "        W = np.diag(np.multiply(p,1-p).reshape(-1,1).T[0])\n",
    "        # define - H^{-1} S\n",
    "        inc = np.linalg.inv(X.T @ W @ X) @ (X.T @ (y - p))\n",
    "        # define B_{t+1} = B_{t} - H^{-1} S = B_{t} + (XWX^T)^{-1}X(y-p)\n",
    "        beta_ = beta + inc\n",
    "        norm_ = norm(beta_, beta)\n",
    "        if norm_ < tol: # convergence check\n",
    "            converged = True\n",
    "            return beta_\n",
    "        else:\n",
    "            beta = beta_\n",
    "            count = count + 1\n",
    "\n",
    "beta = get_beta(X_train,y_train, max_iter = 1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We report the first 5 components of the optimum value of the logistic parameter $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07138813],\n",
       "       [-0.00188321],\n",
       "       [ 0.00781259],\n",
       "       [ 0.01185498],\n",
       "       [ 0.00177207]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we only have 2 classes, 1 or 0, $L_{hat}(h) = 1/n (\\Sigma(I|h(x_i)-y_i|=1))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now determine the resulting training error and test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 3.0259%\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = (1 * (sigmoid(beta.T @ X_train.T) >= 0.5)).reshape(-1,1)\n",
    "training_error = error(y_true = y_train, y_pred = y_pred_train)\n",
    "\n",
    "print('Training error: {}%'.format(round(training_error * 100,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 48.411%\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = (1 * (sigmoid(beta.T @ X_test.T) >= 0.5)).reshape(-1,1)\n",
    "test_error = error(y_true = y_test, y_pred = y_pred_test)\n",
    "\n",
    "print('Test error: {}%'.format(round(test_error * 100,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
